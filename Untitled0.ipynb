{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1UIS8H4PKdNynqDAyDi71cdmLh64cNfM3",
      "authorship_tag": "ABX9TyNyhdgbCmalzikzZCX0Ilvf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/red-hai/-/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYOcwVwEFD-N",
        "outputId": "728b8c0c-cb05-494a-8be6-b51a18051e57"
      },
      "source": [
        "!cd ./drive"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 0: cd: ./drive: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNr2FMkjFcJB",
        "outputId": "c43d57ea-4895-4ca5-dd3f-06be8ac727e8"
      },
      "source": [
        "!cd drive"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 0: cd: drive: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6b913WaFj-f"
      },
      "source": [
        "!cd /content/drive/MyDrive/chx"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDQwfSvQFNTJ"
      },
      "source": [
        "!ls ./drive/MyDrive"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYD7V7S1_cOU"
      },
      "source": [
        "!rm -rf /content/drive/MyDrive/chx"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRMJA8raAQLi"
      },
      "source": [
        "!rm -rf /content/drive/MyDrive/chxsave"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYl2B5kFgXj-"
      },
      "source": [
        "!cp /content/resa/test_label.json /content/drive/MyDrive/chx"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LECcuVpQtMfL"
      },
      "source": [
        "!wget https://s3.us-east-2.amazonaws.com/benchmark-frontend/datasets/1/test_set.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBY9atgWBHTJ"
      },
      "source": [
        "!7za x test_set.zip -o/content/drive/MyDrive/chx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3skW13H6CfhY"
      },
      "source": [
        "!wget https://s3.us-east-2.amazonaws.com/benchmark-frontend/datasets/1/train_set.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XrHMXE7tChzg"
      },
      "source": [
        "!7za x train_set.zip -o/content/drive/MyDrive/chx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfv2ZCaBakfj"
      },
      "source": [
        "!wget https://s3.us-east-2.amazonaws.com/benchmark-frontend/truth/1/test_label.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQOdyLLLdkHq"
      },
      "source": [
        "!wget https://s3.us-east-2.amazonaws.com/benchmark-frontend/truth/2/gt.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPvqmVjiCkUr",
        "outputId": "aa8645a6-b976-4872-ffd7-bd1b2f0af40f"
      },
      "source": [
        "! /opt/bin/nvidia-smi"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 22 06:30:34 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   66C    P8    34W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJMuImELCnlv",
        "outputId": "3d352114-44d1-4051-900d-0a99a1588ecf"
      },
      "source": [
        "cd /content"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KplkbfoXCqkt",
        "outputId": "a07d0001-8e46-4fea-ae1d-e3c2c12d4e22"
      },
      "source": [
        "!git clone https://github.com/ZJULearning/resa.git"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'resa' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpdZIXLOCsor",
        "outputId": "1289bb6d-e335-402c-fa6c-6b689cca989f"
      },
      "source": [
        "cd ./resa"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/resa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CLdAge-CtiV",
        "outputId": "c6e84949-83af-4c26-91ac-9b2f3a8517d2"
      },
      "source": [
        "!pip install -r requirement.txt\n",
        "!pip install pytorch_warmup\n",
        "!pip install yapf"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 1)) (1.1.5)\n",
            "Collecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 3)) (0.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 4)) (4.1.2.30)\n",
            "Collecting pytorch_warmup\n",
            "  Downloading pytorch_warmup-0.0.4-py3-none-any.whl (6.5 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 6)) (0.18.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 7)) (4.62.3)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from -r requirement.txt (line 8)) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirement.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirement.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirement.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->-r requirement.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->-r requirement.txt (line 3)) (1.0.1)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_warmup->-r requirement.txt (line 5)) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1->pytorch_warmup->-r requirement.txt (line 5)) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirement.txt (line 6)) (7.1.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirement.txt (line 6)) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirement.txt (line 6)) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirement.txt (line 6)) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirement.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirement.txt (line 6)) (2.4.1)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->-r requirement.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirement.txt (line 6)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirement.txt (line 6)) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->-r requirement.txt (line 6)) (3.0.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r requirement.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->-r requirement.txt (line 3)) (3.0.0)\n",
            "Installing collected packages: pytorch-warmup, addict\n",
            "Successfully installed addict-2.4.0 pytorch-warmup-0.0.4\n",
            "Requirement already satisfied: pytorch_warmup in /usr/local/lib/python3.7/dist-packages (0.0.4)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_warmup) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.1->pytorch_warmup) (3.10.0.2)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.31.0-py2.py3-none-any.whl (185 kB)\n",
            "\u001b[K     |████████████████████████████████| 185 kB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: yapf\n",
            "Successfully installed yapf-0.31.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67gqmzF-CvOX"
      },
      "source": [
        "dataset_path = '/content/drive/MyDrive/chx'\n",
        "test_json_file = '/content/drive/MyDrive/chx/test_label.json'"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xYkwotGebHG",
        "outputId": "41256487-3909-4db7-a92f-e138fe82e54c"
      },
      "source": [
        "!python tools/generate_seg_tusimple.py --root /content/drive/MyDrive/chx\n",
        "# this will generate seg_label directory"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "generating train_val set...\n",
            "generating test set...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15LhmnhWCyWq",
        "outputId": "8c353a6a-0902-4ce8-a2bb-392abd6df221"
      },
      "source": [
        "!python main.py configs/tusimple.py --gpus 0 --work_dirs /content/drive/MyDrive/chxsave"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-11-22 07:24:34,762 - resa - INFO - Config: \n",
            "/content/resa/configs/tusimple.py\n",
            "net = dict(\n",
            "    type='RESANet',\n",
            ")\n",
            "\n",
            "backbone = dict(\n",
            "    type='ResNetWrapper',\n",
            "    resnet='resnet34',\n",
            "    pretrained=True,\n",
            "    replace_stride_with_dilation=[False, True, True],\n",
            "    out_conv=True,\n",
            "    fea_stride=8,\n",
            ")\n",
            "\n",
            "resa = dict(\n",
            "    type='RESA',\n",
            "    alpha=2.0,\n",
            "    iter=5,\n",
            "    input_channel=128,\n",
            "    conv_stride=9,\n",
            ")\n",
            "\n",
            "decoder = 'BUSD'        \n",
            "\n",
            "trainer = dict(\n",
            "    type='RESA'\n",
            ")\n",
            "\n",
            "evaluator = dict(\n",
            "    type='Tusimple',        \n",
            "    thresh = 0.60\n",
            ")\n",
            "\n",
            "optimizer = dict(\n",
            "  type='sgd',\n",
            "  lr=0.020,\n",
            "  weight_decay=1e-4,\n",
            "  momentum=0.9\n",
            ")\n",
            "\n",
            "total_iter = 80000\n",
            "import math\n",
            "scheduler = dict(\n",
            "    type = 'LambdaLR',\n",
            "    lr_lambda = lambda _iter : math.pow(1 - _iter/total_iter, 0.9)\n",
            ")\n",
            "\n",
            "bg_weight = 0.4\n",
            "\n",
            "img_norm = dict(\n",
            "    mean=[103.939, 116.779, 123.68],\n",
            "    std=[1., 1., 1.]\n",
            ")\n",
            "\n",
            "img_height = 368\n",
            "img_width = 640\n",
            "cut_height = 160\n",
            "seg_label = \"seg_label\"\n",
            "\n",
            "dataset_path = '/content/drive/MyDrive/chx'\n",
            "test_json_file = '/content/drive/MyDrive/chx/test_label.json'\n",
            "\n",
            "dataset = dict(\n",
            "    train=dict(\n",
            "        type='TuSimple',\n",
            "        img_path=dataset_path,\n",
            "        data_list='train_val_gt.txt',\n",
            "    ),\n",
            "    val=dict(\n",
            "        type='TuSimple',\n",
            "        img_path=dataset_path,\n",
            "        data_list='test_gt.txt'\n",
            "    ),\n",
            "    test=dict(\n",
            "        type='TuSimple',\n",
            "        img_path=dataset_path,\n",
            "        data_list='test_gt.txt'\n",
            "    )\n",
            ")\n",
            "\n",
            "\n",
            "loss_type = 'cross_entropy'\n",
            "seg_loss_weight = 1.0\n",
            "\n",
            "\n",
            "batch_size = 4\n",
            "workers = 12\n",
            "num_classes = 6 + 1\n",
            "ignore_label = 255\n",
            "epochs = 300\n",
            "log_interval = 100\n",
            "eval_ep = 1\n",
            "save_ep = epochs\n",
            "log_note = ''\n",
            "\n",
            "2021-11-22 07:24:38,016 - resa - INFO - Network: \n",
            "DataParallel(\n",
            "  (module): RESANet(\n",
            "    (backbone): ResNetWrapper(\n",
            "      (model): ResNet(\n",
            "        (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "        (layer1): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (2): BasicBlock(\n",
            "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (layer2): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (2): BasicBlock(\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (3): BasicBlock(\n",
            "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (layer3): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (2): BasicBlock(\n",
            "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (3): BasicBlock(\n",
            "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (4): BasicBlock(\n",
            "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (5): BasicBlock(\n",
            "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "        (layer4): Sequential(\n",
            "          (0): BasicBlock(\n",
            "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (downsample): Sequential(\n",
            "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            )\n",
            "          )\n",
            "          (1): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "          (2): BasicBlock(\n",
            "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "            (relu): ReLU(inplace=True)\n",
            "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)\n",
            "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (out): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (resa): RESA(\n",
            "      (conv_d0): Conv2d(128, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
            "      (conv_u0): Conv2d(128, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
            "      (conv_r0): Conv2d(128, 128, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
            "      (conv_l0): Conv2d(128, 128, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
            "      (conv_d1): Conv2d(128, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
            "      (conv_u1): Conv2d(128, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
            "      (conv_r1): Conv2d(128, 128, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
            "      (conv_l1): Conv2d(128, 128, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
            "      (conv_d2): Conv2d(128, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
            "      (conv_u2): Conv2d(128, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
            "      (conv_r2): Conv2d(128, 128, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
            "      (conv_l2): Conv2d(128, 128, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
            "      (conv_d3): Conv2d(128, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
            "      (conv_u3): Conv2d(128, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
            "      (conv_r3): Conv2d(128, 128, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
            "      (conv_l3): Conv2d(128, 128, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
            "      (conv_d4): Conv2d(128, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
            "      (conv_u4): Conv2d(128, 128, kernel_size=(1, 9), stride=(1, 1), padding=(0, 4), bias=False)\n",
            "      (conv_r4): Conv2d(128, 128, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
            "      (conv_l4): Conv2d(128, 128, kernel_size=(9, 1), stride=(1, 1), padding=(4, 0), bias=False)\n",
            "    )\n",
            "    (decoder): BUSD(\n",
            "      (layers): ModuleList(\n",
            "        (0): UpsamplerBlock(\n",
            "          (conv): ConvTranspose2d(128, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (follows): ModuleList(\n",
            "            (0): non_bottleneck_1d(\n",
            "              (conv3x1_1): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "              (conv1x3_1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
            "              (bn1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (conv3x1_2): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "              (conv1x3_2): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
            "              (bn2): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (dropout): Dropout2d(p=0, inplace=False)\n",
            "            )\n",
            "            (1): non_bottleneck_1d(\n",
            "              (conv3x1_1): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "              (conv1x3_1): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
            "              (bn1): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (conv3x1_2): Conv2d(64, 64, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "              (conv1x3_2): Conv2d(64, 64, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
            "              (bn2): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (dropout): Dropout2d(p=0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (interpolate_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (interpolate_bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (1): UpsamplerBlock(\n",
            "          (conv): ConvTranspose2d(64, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (follows): ModuleList(\n",
            "            (0): non_bottleneck_1d(\n",
            "              (conv3x1_1): Conv2d(32, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "              (conv1x3_1): Conv2d(32, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
            "              (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (conv3x1_2): Conv2d(32, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "              (conv1x3_2): Conv2d(32, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
            "              (bn2): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (dropout): Dropout2d(p=0, inplace=False)\n",
            "            )\n",
            "            (1): non_bottleneck_1d(\n",
            "              (conv3x1_1): Conv2d(32, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "              (conv1x3_1): Conv2d(32, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
            "              (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (conv3x1_2): Conv2d(32, 32, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "              (conv1x3_2): Conv2d(32, 32, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
            "              (bn2): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (dropout): Dropout2d(p=0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (interpolate_conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (interpolate_bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "        (2): UpsamplerBlock(\n",
            "          (conv): ConvTranspose2d(32, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), output_padding=(1, 1))\n",
            "          (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (follows): ModuleList(\n",
            "            (0): non_bottleneck_1d(\n",
            "              (conv3x1_1): Conv2d(16, 16, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "              (conv1x3_1): Conv2d(16, 16, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
            "              (bn1): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (conv3x1_2): Conv2d(16, 16, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "              (conv1x3_2): Conv2d(16, 16, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
            "              (bn2): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (dropout): Dropout2d(p=0, inplace=False)\n",
            "            )\n",
            "            (1): non_bottleneck_1d(\n",
            "              (conv3x1_1): Conv2d(16, 16, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "              (conv1x3_1): Conv2d(16, 16, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
            "              (bn1): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (conv3x1_2): Conv2d(16, 16, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0))\n",
            "              (conv1x3_2): Conv2d(16, 16, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1))\n",
            "              (bn2): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              (dropout): Dropout2d(p=0, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (interpolate_conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "          (interpolate_bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (output_conv): Conv2d(16, 7, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (heads): ExistHead(\n",
            "      (dropout): Dropout2d(p=0.1, inplace=False)\n",
            "      (conv8): Conv2d(128, 7, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (fc9): Linear(in_features=6440, out_features=128, bias=True)\n",
            "      (fc10): Linear(in_features=128, out_features=6, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "2021-11-22 07:24:38,084 - resa - INFO - start training...\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "2021-11-22 07:24:58,209 - resa - INFO - epoch: 0  step: 1  lr: 0.0000  seg_loss: 2.6740  exist_loss: 0.0641  data: 3.5460  batch: 20.0972  eta: 18 days, 14:35:58\n",
            "2021-11-22 07:28:26,329 - resa - INFO - epoch: 0  step: 101  lr: 0.0004  seg_loss: 0.7843  exist_loss: 0.0652  data: 0.0707  batch: 2.0708  eta: 2 days, 2:08:05\n",
            "2021-11-22 07:31:53,958 - resa - INFO - epoch: 0  step: 201  lr: 0.0008  seg_loss: 0.5684  exist_loss: 0.0631  data: 0.0720  batch: 2.0871  eta: 2 days, 0:03:27\n",
            "2021-11-22 07:35:22,774 - resa - INFO - epoch: 0  step: 301  lr: 0.0012  seg_loss: 0.5295  exist_loss: 0.0621  data: 0.0719  batch: 2.0871  eta: 1 day, 23:24:36\n",
            "2021-11-22 07:38:51,422 - resa - INFO - epoch: 0  step: 401  lr: 0.0016  seg_loss: 0.4816  exist_loss: 0.0593  data: 0.0718  batch: 2.0810  eta: 1 day, 23:02:49\n",
            "2021-11-22 07:42:20,196 - resa - INFO - epoch: 0  step: 501  lr: 0.0020  seg_loss: 0.4372  exist_loss: 0.0575  data: 0.0721  batch: 2.0880  eta: 1 day, 22:48:40\n",
            "2021-11-22 07:45:49,067 - resa - INFO - epoch: 0  step: 601  lr: 0.0024  seg_loss: 0.3928  exist_loss: 0.0550  data: 0.0723  batch: 2.0905  eta: 1 day, 22:38:18\n",
            "2021-11-22 07:49:17,526 - resa - INFO - epoch: 0  step: 701  lr: 0.0028  seg_loss: 0.3439  exist_loss: 0.0529  data: 0.0719  batch: 2.0851  eta: 1 day, 22:29:07\n",
            "2021-11-22 07:52:46,186 - resa - INFO - epoch: 0  step: 801  lr: 0.0032  seg_loss: 0.3145  exist_loss: 0.0517  data: 0.0721  batch: 2.0876  eta: 1 day, 22:21:41\n",
            "2021-11-22 07:56:14,001 - resa - INFO - epoch: 0  step: 901  lr: 0.0036  seg_loss: 0.2855  exist_loss: 0.0509  data: 0.0705  batch: 2.0686  eta: 1 day, 22:13:54\n",
            "2021-11-22 07:56:36,427 - resa - INFO - epoch: 0  step: 907  lr: 0.0036  seg_loss: 0.2895  exist_loss: 0.0509  data: 0.0703  batch: 2.5620  eta: 1 day, 22:27:46\n",
            "Validate: 100% 696/696 [08:27<00:00,  1.37it/s]\n",
            "2021-11-22 08:05:10,368 - resa - INFO - [{\"name\": \"Accuracy\", \"value\": 0.43022962240251905, \"order\": \"desc\"}, {\"name\": \"FP\", \"value\": 0.9054636951833214, \"order\": \"asc\"}, {\"name\": \"FN\", \"value\": 0.9761262880421762, \"order\": \"asc\"}]\n",
            "2021-11-22 08:05:11,506 - resa - INFO - Best metric: 0.43022962240251905\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "2021-11-22 08:05:17,329 - resa - INFO - epoch: 1  step: 908  lr: 0.0036  seg_loss: 0.2845  exist_loss: 0.0512  data: 0.2352  batch: 2.7458  eta: 1 day, 22:33:00\n",
            "2021-11-22 08:08:44,774 - resa - INFO - epoch: 1  step: 1008  lr: 0.0040  seg_loss: 0.2675  exist_loss: 0.0488  data: 0.0703  batch: 2.0731  eta: 1 day, 22:23:41\n",
            "2021-11-22 08:12:11,992 - resa - INFO - epoch: 1  step: 1108  lr: 0.0044  seg_loss: 0.2498  exist_loss: 0.0492  data: 0.0705  batch: 2.0725  eta: 1 day, 22:15:09\n",
            "2021-11-22 08:15:39,020 - resa - INFO - epoch: 1  step: 1208  lr: 0.0048  seg_loss: 0.2538  exist_loss: 0.0495  data: 0.0703  batch: 2.0689  eta: 1 day, 22:07:15\n",
            "2021-11-22 08:19:06,116 - resa - INFO - epoch: 1  step: 1308  lr: 0.0052  seg_loss: 0.2297  exist_loss: 0.0495  data: 0.0709  batch: 2.0715  eta: 1 day, 22:00:06\n",
            "2021-11-22 08:22:33,303 - resa - INFO - epoch: 1  step: 1408  lr: 0.0055  seg_loss: 0.2457  exist_loss: 0.0490  data: 0.0706  batch: 2.0725  eta: 1 day, 21:53:33\n",
            "2021-11-22 08:26:00,484 - resa - INFO - epoch: 1  step: 1508  lr: 0.0059  seg_loss: 0.2374  exist_loss: 0.0485  data: 0.0705  batch: 2.0727  eta: 1 day, 21:47:25\n",
            "2021-11-22 08:29:27,720 - resa - INFO - epoch: 1  step: 1608  lr: 0.0063  seg_loss: 0.1861  exist_loss: 0.0493  data: 0.0709  batch: 2.0729  eta: 1 day, 21:41:40\n",
            "2021-11-22 08:32:54,875 - resa - INFO - epoch: 1  step: 1708  lr: 0.0067  seg_loss: 0.1913  exist_loss: 0.0488  data: 0.0706  batch: 2.0732  eta: 1 day, 21:36:07\n",
            "2021-11-22 08:36:21,972 - resa - INFO - epoch: 1  step: 1808  lr: 0.0071  seg_loss: 0.1520  exist_loss: 0.0502  data: 0.0704  batch: 2.0696  eta: 1 day, 21:30:45\n",
            "2021-11-22 08:36:33,429 - resa - INFO - epoch: 1  step: 1814  lr: 0.0071  seg_loss: 0.1514  exist_loss: 0.0506  data: 0.0705  batch: 2.0210  eta: 1 day, 21:29:45\n",
            "Validate: 100% 696/696 [08:01<00:00,  1.45it/s]\n",
            "2021-11-22 08:44:43,521 - resa - INFO - [{\"name\": \"Accuracy\", \"value\": 0.8038586705350724, \"order\": \"desc\"}, {\"name\": \"FP\", \"value\": 0.4151389887371216, \"order\": \"asc\"}, {\"name\": \"FN\", \"value\": 0.43329139707644565, \"order\": \"asc\"}]\n",
            "2021-11-22 08:44:44,698 - resa - INFO - Best metric: 0.8038586705350724\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "2021-11-22 08:44:50,311 - resa - INFO - epoch: 2  step: 1815  lr: 0.0071  seg_loss: 0.1481  exist_loss: 0.0506  data: 0.2076  batch: 2.1952  eta: 1 day, 21:32:12\n",
            "2021-11-22 08:48:17,642 - resa - INFO - epoch: 2  step: 1915  lr: 0.0075  seg_loss: 0.1443  exist_loss: 0.0498  data: 0.0706  batch: 2.0725  eta: 1 day, 21:27:06\n",
            "2021-11-22 08:51:44,742 - resa - INFO - epoch: 2  step: 2015  lr: 0.0079  seg_loss: 0.1664  exist_loss: 0.0491  data: 0.0705  batch: 2.0691  eta: 1 day, 21:22:02\n",
            "2021-11-22 08:55:11,833 - resa - INFO - epoch: 2  step: 2115  lr: 0.0083  seg_loss: 0.1473  exist_loss: 0.0477  data: 0.0705  batch: 2.0718  eta: 1 day, 21:17:07\n",
            "2021-11-22 08:58:38,896 - resa - INFO - epoch: 2  step: 2215  lr: 0.0086  seg_loss: 0.1407  exist_loss: 0.0495  data: 0.0705  batch: 2.0700  eta: 1 day, 21:12:18\n",
            "2021-11-22 09:02:05,948 - resa - INFO - epoch: 2  step: 2315  lr: 0.0090  seg_loss: 0.1322  exist_loss: 0.0485  data: 0.0702  batch: 2.0710  eta: 1 day, 21:07:36\n",
            "2021-11-22 09:05:33,060 - resa - INFO - epoch: 2  step: 2415  lr: 0.0094  seg_loss: 0.1277  exist_loss: 0.0493  data: 0.0704  batch: 2.0687  eta: 1 day, 21:03:03\n",
            "2021-11-22 09:09:00,260 - resa - INFO - epoch: 2  step: 2515  lr: 0.0098  seg_loss: 0.1333  exist_loss: 0.0478  data: 0.0706  batch: 2.0717  eta: 1 day, 20:58:37\n",
            "2021-11-22 09:12:27,211 - resa - INFO - epoch: 2  step: 2615  lr: 0.0102  seg_loss: 0.1184  exist_loss: 0.0478  data: 0.0703  batch: 2.0703  eta: 1 day, 20:54:08\n",
            "2021-11-22 09:15:54,095 - resa - INFO - epoch: 2  step: 2715  lr: 0.0105  seg_loss: 0.1178  exist_loss: 0.0478  data: 0.0704  batch: 2.0672  eta: 1 day, 20:49:42\n",
            "2021-11-22 09:16:05,544 - resa - INFO - epoch: 2  step: 2721  lr: 0.0106  seg_loss: 0.1182  exist_loss: 0.0474  data: 0.0704  batch: 2.0195  eta: 1 day, 20:49:00\n",
            "Validate: 100% 696/696 [07:59<00:00,  1.45it/s]\n",
            "2021-11-22 09:24:13,651 - resa - INFO - [{\"name\": \"Accuracy\", \"value\": 0.9245441571668168, \"order\": \"desc\"}, {\"name\": \"FP\", \"value\": 0.11987778576563625, \"order\": \"asc\"}, {\"name\": \"FN\", \"value\": 0.13215911814042647, \"order\": \"asc\"}]\n",
            "2021-11-22 09:24:14,843 - resa - INFO - Best metric: 0.9245441571668168\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "2021-11-22 09:24:20,534 - resa - INFO - epoch: 3  step: 2722  lr: 0.0106  seg_loss: 0.1152  exist_loss: 0.0474  data: 0.2165  batch: 2.1978  eta: 1 day, 20:50:38\n",
            "2021-11-22 09:27:47,609 - resa - INFO - epoch: 3  step: 2822  lr: 0.0109  seg_loss: 0.1381  exist_loss: 0.0488  data: 0.0711  batch: 2.0685  eta: 1 day, 20:46:19\n",
            "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f585e27e440>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1328, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1301, in _shutdown_workers\n",
            "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
            "    res = self._popen.wait(timeout)\n",
            "  File \"/usr/lib/python3.7/multiprocessing/popen_fork.py\", line 45, in wait\n",
            "    if not wait([self.sentinel], timeout):\n",
            "  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 921, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.7/selectors.py\", line 415, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "KeyboardInterrupt: \n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 73, in <module>\n",
            "    main()\n",
            "  File \"main.py\", line 42, in main\n",
            "    runner.train()\n",
            "  File \"/content/resa/runner/runner.py\", line 81, in train\n",
            "    self.train_epoch(epoch, train_loader)\n",
            "  File \"/content/resa/runner/runner.py\", line 54, in train_epoch\n",
            "    data = self.to_cuda(data)\n",
            "  File \"/content/resa/runner/runner.py\", line 42, in to_cuda\n",
            "    batch[k] = batch[k].cuda()\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    }
  ]
}